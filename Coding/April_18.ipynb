{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk, re, pprint\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read the training data\n",
    "df_train = pd.read_csv(\"/Users/shijiabian/Dropbox/Duke Statistics Courses/Spring 2016 Duke Course/STA 571 Adv ML/Final Project/Data/train.csv\", encoding=\"ISO-8859-1\") #update here\n",
    "df_test = pd.read_csv(\"/Users/shijiabian/Dropbox/Duke Statistics Courses/Spring 2016 Duke Course/STA 571 Adv ML/Final Project/Data/test.csv\", encoding=\"ISO-8859-1\") #update here\n",
    "df_att = pd.read_csv(\"/Users/shijiabian/Dropbox/Duke Statistics Courses/Spring 2016 Duke Course/STA 571 Adv ML/Final Project/Data/attributes.csv\", encoding=\"ISO-8859-1\") #update here\n",
    "df_pro = pd.read_csv(\"/Users/shijiabian/Dropbox/Duke Statistics Courses/Spring 2016 Duke Course/STA 571 Adv ML/Final Project/Data/product_descriptions.csv\", encoding=\"ISO-8859-1\") #update here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_df = pd.DataFrame(df_train)\n",
    "df_train_pro = pd.DataFrame(df_pro)\n",
    "df_test_df = pd.DataFrame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = pd.merge(df_train_df, df_train_pro, on='product_uid')\n",
    "result_test = pd.merge(df_test_df, df_train_pro, on='product_uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function for splitting the words\n",
    "def split_search(value) :\n",
    "    res = [w.lower() for w in (str(value).split())]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a new column called search_split\n",
    "ss = result[\"search_term\"].apply(split_search) \n",
    "result['search_split'] = pd.Series(ss, index=result.index)\n",
    "ss = result_test[\"search_term\"].apply(split_search) \n",
    "result_test['search_split'] = pd.Series(ss, index=result_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# help to split the string\n",
    "def split_search(value) :\n",
    "    res = [w.lower() for w in (str(value).split())]\n",
    "    return res\n",
    "\n",
    "# calculate the word length for each of the searching words\n",
    "# remove the word that has length 1\n",
    "nrow = result.shape[0]\n",
    "new_search_split = [0]*nrow\n",
    "for index, row in result.iterrows():\n",
    "    each_word_len = [len(w) for w in row[\"search_split\"]]\n",
    "    row[\"search_split\"] = [word for word in row[\"search_split\"] if len(word) > 1]\n",
    "    new_search_split[index] = row[\"search_split\"]\n",
    "    each_word_len = [mm for mm in each_word_len if mm > 1]\n",
    "\n",
    "# add a new column called search_split\n",
    "result['new_search_split'] = pd.Series(new_search_split, index=result.index)\n",
    "\n",
    "# help to split the string for test data\n",
    "def split_search(value) :\n",
    "    res = [w.lower() for w in (str(value).split())]\n",
    "    return res\n",
    "\n",
    "# calculate the word length for each of the searching words\n",
    "# remove the word that has length 1\n",
    "\n",
    "nrow = result_test.shape[0]\n",
    "new_search_split = [0]*nrow\n",
    "for index, row in result_test.iterrows():\n",
    "    each_word_len = [len(str(w)) for w in row[\"search_split\"]]\n",
    "    row[\"search_split\"] = [word for word in row[\"search_split\"] if len(word) > 1]\n",
    "    new_search_split[index] = row[\"search_split\"]\n",
    "    each_word_len = [mm for mm in each_word_len if mm > 1]\n",
    "\n",
    "# add a new column called search_split\n",
    "result_test['new_search_split'] = pd.Series(new_search_split, index=result_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find how many words in the product description match the searching query \n",
    "nrow = result.shape[0]\n",
    "desc_match_word = [0]*nrow\n",
    "for index, row in result.iterrows():\n",
    "    ll = [len(re.findall(w, row[\"product_description\"])) for w in row[\"new_search_split\"]]\n",
    "    desc_match_word[index] = sum(ll)\n",
    "\n",
    "# add a new column called description match words\n",
    "result['desc_match_word'] = pd.Series(desc_match_word, index=result.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#result_test[\"product_description\"][73024] = result_test[\"product_description\"][1]\n",
    "#result_test[\"new_search_split\"][73024] = result_test[\"new_search_split\"][1]\n",
    "#118900\n",
    "# 118901\n",
    "# find how many words in the product description match the searching query \n",
    "nrow = result_test.shape[0]\n",
    "desc_match_word = [0]*nrow\n",
    "for index, row in result_test.iterrows():    \n",
    "    ll = [len(re.findall(w, row[\"product_description\"])) for w in row[\"new_search_split\"]]\n",
    "    print (ll)\n",
    "    desc_match_word[index] = sum(ll)\n",
    "result_test['desc_match_word'] = pd.Series(desc_match_word, index=result_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find how many words match in the product title\n",
    "nrow = result.shape[0]\n",
    "title_match_word = [0]*nrow\n",
    "for index, row in result.iterrows():\n",
    "    ll = [len(re.findall(w, str(row[\"product_title\"]).lower())) for w in row[\"new_search_split\"]]\n",
    "    print (ll)\n",
    "    print(index)\n",
    "    title_match_word[index] = sum(ll)\n",
    "\n",
    "# add a new column called description match words\n",
    "result['title_match_word'] = pd.Series(title_match_word, index=result.index)\n",
    "\n",
    "# test data\n",
    "# find how many words match in the product title\n",
    "nrow = result_test.shape[0]\n",
    "title_match_word = [0]*nrow\n",
    "for index, row in result_test.iterrows():\n",
    "    ll = [len(re.findall(w, str(row[\"product_title\"]).lower())) for w in row[\"new_search_split\"]]\n",
    "    print (ll)\n",
    "    print(index)\n",
    "    title_match_word[index] = sum(ll)\n",
    "\n",
    "# add a new column called description match words\n",
    "result_test['title_match_word'] = pd.Series(title_match_word, index=result_test.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 737,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
       "            criterion='gini', max_depth=None, max_features='auto',\n",
       "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
       "            min_samples_split=2, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0)"
      ]
     },
     "execution_count": 737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build random forest model\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cols = ['desc_match_word', 'title_match_word'] \n",
    "colsRes = ['relevance']\n",
    "trainArr = result.as_matrix(cols) #training array\n",
    "trainRes = result.as_matrix(colsRes) # training results\n",
    "rf = RandomForestClassifier(n_estimators=100) # initialize\n",
    "rf.fit(trainArr, trainRes) # fit the data to the algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166693,)"
      ]
     },
     "execution_count": 749,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testArr = result_test.as_matrix(cols)\n",
    "results = rf.predict(testArr)\n",
    "relevance = results\n",
    "relevance.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = list(range(166694))[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166664</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166665</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166666</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166667</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166668</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166669</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166670</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166671</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166672</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166673</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166674</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166675</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166676</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166677</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166678</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166679</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166680</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166681</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166682</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166683</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166684</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166685</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166686</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166687</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166688</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166689</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166690</th>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166691</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166692</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166693</th>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>166693 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "1       2.33\n",
       "2       2.33\n",
       "3       3.00\n",
       "4       3.00\n",
       "5       3.00\n",
       "6       2.33\n",
       "7       3.00\n",
       "8       3.00\n",
       "9       3.00\n",
       "10      3.00\n",
       "11      3.00\n",
       "12      3.00\n",
       "13      2.33\n",
       "14      3.00\n",
       "15      3.00\n",
       "16      3.00\n",
       "17      2.33\n",
       "18      2.33\n",
       "19      1.67\n",
       "20      2.00\n",
       "21      3.00\n",
       "22      2.33\n",
       "23      2.00\n",
       "24      3.00\n",
       "25      2.33\n",
       "26      3.00\n",
       "27      2.33\n",
       "28      2.33\n",
       "29      3.00\n",
       "30      3.00\n",
       "...      ...\n",
       "166664  3.00\n",
       "166665  3.00\n",
       "166666  3.00\n",
       "166667  3.00\n",
       "166668  3.00\n",
       "166669  3.00\n",
       "166670  3.00\n",
       "166671  3.00\n",
       "166672  3.00\n",
       "166673  3.00\n",
       "166674  3.00\n",
       "166675  2.33\n",
       "166676  3.00\n",
       "166677  2.33\n",
       "166678  3.00\n",
       "166679  3.00\n",
       "166680  3.00\n",
       "166681  2.33\n",
       "166682  3.00\n",
       "166683  3.00\n",
       "166684  3.00\n",
       "166685  2.33\n",
       "166686  2.33\n",
       "166687  3.00\n",
       "166688  3.00\n",
       "166689  3.00\n",
       "166690  2.33\n",
       "166691  3.00\n",
       "166692  3.00\n",
       "166693  3.00\n",
       "\n",
       "[166693 rows x 1 columns]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(index = index, data=relevance)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/shijiabian/Dropbox/Duke Statistics Courses/Spring 2016 Duke Course/STA 571 Adv ML/Final Project/submission/sub_4_20.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneT = str(result[\"product_title\"][2]).lower()\n",
    "m=re.findall(r\"premium\", str(result[\"product_title\"][2]).lower())\n",
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "bracket\n"
     ]
    }
   ],
   "source": [
    "for w in (str(result[\"search_term\"][1]).split()):\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0',\n",
       " 'angle',\n",
       " 'bracket',\n",
       " '1',\n",
       " 'l',\n",
       " 'bracket',\n",
       " '2',\n",
       " 'deck',\n",
       " 'over',\n",
       " '3',\n",
       " 'rain',\n",
       " 'shower',\n",
       " 'head',\n",
       " '4',\n",
       " 'shower',\n",
       " 'only',\n",
       " 'faucet',\n",
       " '5',\n",
       " 'convection',\n",
       " 'otr',\n",
       " '6',\n",
       " 'microwave',\n",
       " 'over',\n",
       " 'stove',\n",
       " '7',\n",
       " 'microwaves',\n",
       " '8',\n",
       " 'emergency',\n",
       " 'light',\n",
       " '9',\n",
       " 'mdf',\n",
       " '3/4',\n",
       " 'name:',\n",
       " 'search_term,',\n",
       " 'dtype:',\n",
       " 'object']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the words in the searching query\n",
    "[w.lower() for w in (str(result[\"search_term\"]).split())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_search(value) :\n",
    "    res = [w.lower() for w in (str(value).split())]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-217-2b4cedb14511>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"search_term\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_search\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'search_split'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msearch_split\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'search_split' is not defined"
     ]
    }
   ],
   "source": [
    "ss = result[\"search_term\"].apply(split_search) \n",
    "result['search_split'] = pd.Series(ss, index=result.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 7]\n",
      "[7]\n",
      "[4, 4]\n",
      "[4, 6, 4]\n",
      "[6, 4, 6]\n",
      "[10, 3]\n",
      "[9, 4, 5]\n",
      "[10]\n",
      "[9, 5]\n",
      "[3, 3]\n"
     ]
    }
   ],
   "source": [
    "for index, row in result.iterrows():\n",
    "    each_word_len = [len(w) for w in row[\"search_split\"]]\n",
    "    each_word_len = [mm for mm in each_word_len if mm > 1]\n",
    "    print (each_word_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'l bracket'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(ss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneT = str(result[\"product_title\"][2]).lower()\n",
    "m=re.findall(ss[1][1], \"this is a bracket\")\n",
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'angle', u'angle', u'angle']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(ss[0][0], result[\"product_description\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-c14d3b206ed6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"this is a bracket\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_search_term\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"this is a bracket\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 181\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhexversion\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0x02020000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python2.7/re.pyc\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(*key)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mcachekey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcachekey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_locale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLC_CTYPE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "split_search_term = result[\"search_term\"].apply(split_search) \n",
    "text = \"this is a bracket\"\n",
    "for \n",
    "m=re.findall(split_search_term[1], \"this is a bracket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll = [len(re.findall(w, \"this is a bracket\")) for w in split_search_term[1]]\n",
    "ll\n",
    "result.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 20, 4, 0, 1, 2, 8, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "nrow = result.shape[0]\n",
    "match_word = [0]*nrow\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    ll = [len(re.findall(w, row[\"product_description\"])) for w in row[\"search_split\"]]\n",
    "    match_word[index] = sum(ll)\n",
    "    \n",
    "print (match_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
